import torchvision.transforms as transforms
from torchvision import datasets
from torch.autograd import Variable
from tqdm.auto import tqdm
import torch.nn.functional as F
import torch
from Critic import *
import numpy as np
import matplotlib.pyplot as plt
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
from torchvision.utils import make_grid
from IPython.display import clear_output



from Generator import *
from Utils import *

cuda = True if torch.cuda.is_available() else False
Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
device = "cuda"


class Hyperparameters(object):
    def __init__(self, **kwargs):
        self.__dict__.update(kwargs)


n_epochs = 100
z_dim = 64
display_step = 50  # Only for visualization of my output during training
batch_size = 128
lr = 0.0002
beta_1 = 0.5
beta_2 = 0.999
c_lambda = 10

crit_repeats = 5
# Number of times the Critic will be trained for each Generator Training

hp = Hyperparameters(
    n_epochs=1000,
    batch_size=64,
    lr=0.00005,
    n_cpu=8,
    z_dim=64,
    img_size=32,
    channels=1,
    n_critic=25,
    clip_value=0.005,
    sample_interval=400,
)
######################################################################
# Gradient Penalty Calculation -  Calculate Gradient of Critic Score
#######################################################################
def gradient_of_critic_score(critic, real, fake, epsilon):
    """
    Function to compute the gradient of the critic's scores for interpolated images.

    This function is a key component of the Gradient Penalty in WGAN-GP (Wasserstein GAN with Gradient Penalty),
    a popular GAN architecture. The gradient penalty encourages the critic's gradient norms to be close to 1,
    which ensures the 1-Lipschitz constraint needed for the Wasserstein distance function to be valid.

    Args:
        critic (nn.Module): The critic model, typically a neural network.
        real (torch.Tensor): Batch of real images.
        fake (torch.Tensor): Batch of fake images generated by the generator.
        epsilon (float): The weight for the interpolation between real and fake images.

    Returns:
        gradient (torch.Tensor): The computed gradient of the critic's scores for the interpolated images.
    """

    # Create the interpolated images as a weighted combination of real and fake images
    interpolated_images = real * epsilon + fake * (1 - epsilon)

    mixed_scores = critic(interpolated_images)

    gradient = torch.autograd.grad(
        inputs=interpolated_images,
        outputs=mixed_scores,
        grad_outputs=torch.ones_like(mixed_scores),
        create_graph=True,
        retain_graph=True,
    )[0]
    return gradient

""" Whats the significane of the below line in above

interpolated_images = real * epsilon + fake * (1 - epsilon)

 this line is used to enforce a constraint on the gradients of the critic (also called discriminator). This is known as the "gradient penalty".

The idea behind the gradient penalty is to prevent the critic from becoming too powerful, which could cause the generator to fail to learn. This is done by encouraging the gradients of the critic to have a norm of 1 across the image space. To enforce this, we don't just consider the gradients at the real images or the fake images, but also at random points along the straight line between a pair of real and fake images. These points are the "interpolated images".

By computing the gradients at these interpolated images and adding a penalty to the critic's loss function if these gradients deviate from 1, we can ensure that the critic is a 1-Lipschitz function, which is a key property needed for the theoretical guarantees of the Wasserstein distance to hold. This results in more stable training dynamics for the GAN.

So, in essence, the line is generating the interpolated images at which the critic's gradients will be evaluated.

"""


def gradient_penalty_l2_norm(gradient):
    """
    Calculate the L2 norm of the gradient for enforcing the 1-Lipschitz constraint in Wasserstein GAN with Gradient Penalty (WGAN-GP).

    The gradient penalty is calculated as the mean square error of the gradient norms from 1. The gradient penalty encourages the gradients of the critic to be unit norm, which is a key property of 1-Lipschitz functions.

    Args:
    gradient (torch.Tensor): The gradients of the critic's scores with respect to the interpolated images.

    Returns:
    torch.Tensor: The gradient penalty.
    """
    # Reshape each image in the batch into a 1D tensor (flatten the images)
    gradient = gradient.view(len(gradient), -1)

    gradient_norm = gradient.norm(2, dim=1)

    # Calculate the penalty as the mean squared distance of the norms from 1.
    penalty = torch.mean((gradient_norm - 1) ** 2)

    return penalty

root_path =  "D:/Elamathi/Projects/PROJECTS/WGAN_GP_200 EPOCHS/FashionMNIST"
""" The Fashion-MNIST dataset contains 60,000 training images (and 10,000 test images) of fashion and clothing items,
taken from 10 classes. Each image is a standardized 28Ã—28 size in grayscale (784 total pixels). """

dataloader = torch.utils.data.DataLoader(
    datasets.FashionMNIST(
        root_path,
        train=True,
        download=True,
        transform=transforms.Compose(
            [
                transforms.Resize(hp.img_size),
                transforms.ToTensor(),
                transforms.Normalize([0.5], [0.5]),
            ]
        ),
    ),
    batch_size=hp.batch_size,
    shuffle=True,
)



generator = Generator(z_dim).to(device)
gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta_1, beta_2))

critic = Critic().to(device)
critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(beta_1, beta_2))


generator = generator.apply(weights_init)
critic = critic.apply(weights_init)

def save_images_from_tensor(image_tensor, output_dir, epoch, num_images=25, size=(1, 32, 32)):
    # Normalize the image tensor to [0, 1]
    image_tensor = (image_tensor + 1) / 2

    # Detach the tensor from its computation graph and move it to the CPU
    img_detached = image_tensor.detach().cpu()

    # Create a grid of images using the make_grid function from torchvision.utils
    image_grid = make_grid(img_detached[:num_images], nrow=5)

    # Save the grid of images
    os.makedirs(output_dir, exist_ok=True)
    vutils.save_image(image_grid, os.path.join(output_dir, f'epoch_{epoch}.png'))


##############################
# Final Training
##############################

import matplotlib.pyplot as plt
import torchvision.utils as vutils
current_step = 0
generator_losses = []
critic_losses_across_critic_repeats = []
visualize_epoch = [1,2,5,15,30,45,70,100]
current_epoch = 0
for epoch in range(1,(n_epochs+1)):
    print(f"~~~~~~~~~~Epoch {epoch}/{n_epochs}~~~~~~~~~~~~")
    # Dataloader returns the batches
    for real, _ in tqdm(dataloader):
        cur_batch_size = len(real)
        real = real.to(device)

        mean_critic_loss_for_this_iteration = 0
        for _ in range(crit_repeats):

            #########################
            #  Train Critic
            #########################
            critic_optimizer.zero_grad()

            fake_noise = get_noise(cur_batch_size, z_dim, device=device)

            fake = generator(fake_noise)

            critic_fake_prediction = critic(fake.detach())

            crit_real_pred = critic(real)

            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)
            # epsilon will be a Tensor of size torch.Size([128, 1, 1, 1]) for batch_size of 128
            # Generate fake images with the same shape as real
            fake = generator(fake_noise).detach().to(device)
            
            fake = F.interpolate(fake, size=(32, 32), mode='bilinear', align_corners=True)  # Interpolate to match 32x32

            gradient = gradient_of_critic_score(critic, real, fake, epsilon)

            gp = gradient_penalty_l2_norm(gradient)

            crit_loss = get_crit_loss(
                critic_fake_prediction, crit_real_pred, gp, c_lambda
            )

            # Keep track of the average critic loss in this batch
            mean_critic_loss_for_this_iteration += crit_loss.item() / crit_repeats

            # Update gradients
            crit_loss.backward(retain_graph=True)
            # Update optimizer i.e. the weights
            critic_optimizer.step()
        critic_losses_across_critic_repeats += [mean_critic_loss_for_this_iteration]

        #########################
        #  Train Generators
        #########################
        gen_optimizer.zero_grad()

        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)

        fake_2 = generator(fake_noise_2)

        critic_fake_prediction = critic(fake_2)

        gen_loss = get_gen_loss(critic_fake_prediction)

        gen_loss.backward()

        # Update the weights
        gen_optimizer.step()

        # Keep track of the average generator loss
        generator_losses.append(gen_loss.item())
    avg_generator_losses = sum(generator_losses)/len(generator_losses)

    print( f"Step {current_step}: Generator loss: {avg_generator_losses}, critic loss: {mean_critic_loss_for_this_iteration}")
    if epoch == visualize_epoch[current_epoch]:
        # Save real images
        real_image_dir = r'D:/Elamathi/Projects/PROJECTS/WGAN_GP_200 EPOCHS/Figures/REAL IMAGES'
        save_images_from_tensor(real, real_image_dir, epoch)

        # Save generated images
        generated_image_dir = r'D:/Elamathi/Projects/PROJECTS/WGAN_GP_200 EPOCHS/Figures/GENERATED IMAGES'
        save_images_from_tensor(fake, generated_image_dir, epoch)
        loss_image_dir = r'D:/Elamathi/Projects/PROJECTS/WGAN_GP_200 EPOCHS/Figures/LOSS IMAGES'
        os.makedirs(loss_image_dir, exist_ok=True)
        step_bins = 20
        num_examples = (len(generator_losses) // step_bins) * step_bins
        plt.figure()
        plt.plot(
            range(num_examples // step_bins),
            torch.Tensor(generator_losses[:num_examples])
            .view(-1, step_bins)
            .mean(1),
            label="Generator Loss",
        )
        plt.plot(
            range(num_examples // step_bins),
            torch.Tensor(critic_losses_across_critic_repeats[:num_examples])
            .view(-1, step_bins)
            .mean(1),
            label="Critic Loss",
        )
        plt.legend()
        plt.savefig(os.path.join(loss_image_dir, f'loss_plot_epoch_{epoch}.png'))
        plt.close()
        current_epoch += 1
    if current_epoch == len(visualize_epoch):
        break
